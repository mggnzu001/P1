# âœ… **LOGSEQ FLASHCARDS â€” THEORY OF ALGORITHMS**

Flashcard format follows:

```
- TERM â€” description #card
- Q â†’ ...
- A â†’ ...
```

---
- # **BRUTE FORCE**
  
  ---
- ## **Brute Force â€“ General Strategy**
	- Brute Force â€” general description #card
	- Q â†’ What is the brute-force method?
	- A â†’ A direct, naive solution derived exactly from the problem statement; tests all possible candidates or performs operations in the most straightforward way. Includes exhaustive search as a special case.
- Brute Force â€” pros & cons #card
	- Q â†’ What are the pros and cons of brute force?
	- A â†’
	  **Pros:**
		- Simple and widely applicable
		- Easy to implement
		- Often â€œgood enoughâ€ for small inputs
		- Useful as a baseline
		  
		  **Cons:**
		- Rarely efficient
		- Often infeasibly slow for large input sizes
		  
		  ---
- ## **Brute Force String Matching**
	- String Matching â€” problem #card
		- Q â†’ What is the brute-force string-matching problem?
		- A â†’ Given text **T** length n and pattern **P** length m, find the first index where P occurs in T; return â€“1 if no match.
	- String Matching â€” algorithm steps #card
		- Q â†’ What are the steps of brute-force string matching?
		- A â†’
		  
		  1. Align pattern at T[0].
		  2. Compare characters leftâ†’right until mismatch or full match.
		  3. If mismatch, slide pattern 1 position to the right.
		  4. Repeat until T exhausted or match found.
	- String Matching â€” efficiency #card
		- Q â†’ What is the complexity of brute-force string matching?
		- A â†’
			- **Worst case:** Î˜(mÂ·n)
			- **Average case (natural language):** Î˜(n)
	- String Matching â€” worst case scenario #card
	- Q â†’ What causes the worst-case behaviour?
	- A â†’ Pattern matches all characters except the last at each alignment (e.g., T = â€œaaaaaaâ€¦â€, P = â€œaaabâ€).
	  
	  ---
- ## **Brute Force Closest Pair of Points**
	- Closest Pair â€” problem #card
	- Q â†’ What is the brute-force closest-pair problem?
	- A â†’ Given n 2D points, find the pair with minimum Euclidean distance.
- Closest Pair â€” algorithm #card
	- Q â†’ What is the brute-force closest-pair algorithm?
	- A â†’ Compute distance between every pair (nested loops), track smallest.
- Closest Pair â€” complexity #card
	- Q â†’ What is its efficiency?
	- A â†’ Î˜(nÂ²)
- Closest Pair â€” improvement #card
	- Q â†’ What improvements exist?
	- A â†’ Avoid sqrt by comparing squared distances; or use divide-and-conquer for Î˜(n log n).
	  
	  ---
- ## **Brute Force Convex Hull**
- Convex Hull â€” problem #card
	- Q â†’ What is the brute-force convex hull problem?
	- A â†’ Given n points, find the smallest convex polygon enclosing all points.
- Convex Hull â€” brute force algorithm #card
	- Q â†’ What is the brute-force convex hull algorithm?
	- A â†’
	  For every pair of points (p1, p2):
		- Determine if all other points lie on the same side of the line p1â†’p2.
		- If yes, the segment is part of the hull.
	- Convex Hull â€” efficiency #card
		- Q â†’ What is the complexity?
		- A â†’ Î˜(nÂ³)
	- Convex Hull â€” improvement #card
		- Q â†’ How can the brute-force convex hull be improved?
		- A â†’ Use algorithms like Graham Scan Î˜(n log n) or QuickHull (average Î˜(n), worst Î˜(nÂ²)).
		  
		  ---
- # **EXHAUSTIVE SEARCH**
  
  ---
- ## **Exhaustive Search â€” Definition**
	- Exhaustive Search â€” definition #card
	- Q â†’ What is exhaustive search?
	- A â†’ Systematically enumerate all possible solutions, evaluate each, and choose the best feasible one. Often applied to permutations and subsets.
- Exhaustive Search â€” method #card
	- Q â†’ What are the steps?
	- A â†’
	  
	  1. List all candidate solutions systematically.
	  2. Evaluate each (filter infeasible).
	  3. Keep the best solution.
	  
	  ---
- ## **Travelling Salesman Problem (TSP)**
	- TSP â€” problem #card
	- Q â†’ State the TSP.
	- A â†’ Find the shortest Hamiltonian cycle visiting all cities exactly once.
- TSP â€” exhaustive search algorithm #card
	- Q â†’ How do we solve TSP via exhaustive search?
	- A â†’ Generate all permutations of cities (fix start to reduce symmetry) and compute total distance for each.
- TSP â€” efficiency #card
	- Q â†’ What is the complexity?
	- A â†’ Î˜((nâ€“1)!) or (nâ€“1)!/2 with symmetry reduction.
- TSP â€” improvement #card
	- Q â†’ How can exhaustive TSP be improved?
	- A â†’ Branch-and-bound, heuristics (nearest neighbour), dynamic programming (Heldâ€“Karp Î˜(nÂ²2â¿)).
	  
	  ---
- ## **Knapsack (0/1) via Exhaustive Search**
	- Knapsack â€” problem #card
	- Q â†’ State the 0/1 knapsack problem.
	- A â†’ Choose a subset of items with maximum value, with total weight â‰¤ W.
- Knapsack â€” exhaustive search #card
	- Q â†’ What is the exhaustive search solution?
	- A â†’ Enumerate all 2â¿ subsets, compute weight and value, pick best feasible.
- Knapsack â€” efficiency #card
	- Q â†’ Complexity of exhaustive knapsack?
	- A â†’ Î˜(2â¿)
- Knapsack â€” improvement #card
	- Q â†’ Improvements?
	- A â†’ Dynamic programming Î˜(nW), branch-and-bound, greedy only works for fractional Knapsack.
	  
	  ---
- ## **Assignment Problem via Exhaustive Search**
	- Assignment â€” problem #card
	- Q â†’ State the assignment problem.
	- A â†’ Assign n jobs to n people with minimum cost, each job to exactly one person.
- Assignment â€” exhaustive search #card
	- Q â†’ Exhaustive algorithm?
	- A â†’ Generate all permutations of job assignments; compute cost; choose minimum.
- Assignment â€” efficiency #card
	- Q â†’ Complexity?
	- A â†’ Î˜(n!)
- Assignment â€” improvement #card
	- Q â†’ How is assignment solved efficiently?
	- A â†’ Hungarian algorithm Î˜(nÂ³).
	  
	  ---
- ## **BFS / DFS as Exhaustive Search**
	- Graph Traversal â€” BFS vs DFS #card
	- Q â†’ Why are BFS and DFS considered exhaustive search?
	- A â†’ They systematically visit every vertex reachable from a start node.
- BFS/DFS â€” efficiency #card
	- Q â†’ What are their time complexities?
	- A â†’
		- Adjacency list: Î˜(V + E)
		- Adjacency matrix: Î˜(VÂ²)
		  
		  ---
- # **DECREASE & CONQUER**
  
  ---
- ## **General Strategy**
	- Decrease & Conquer â€” definition #card
	- Q â†’ What is decrease-and-conquer?
	- A â†’ Solve a smaller instance of size nâ€“c or n/c, then extend the solution to the original.
- Decrease & Conquer â€” variants #card
	- Q â†’ What are the three types?
	- A â†’
	  
	  1. Decrease by constant (n â†’ nâ€“1)
	  2. Decrease by constant factor (n â†’ n/2)
	  3. Variable decrease (e.g., n â†’ n mod m)
	  
	  ---
- ## **Insertion Sort**
	- Insertion Sort â€” algorithm #card
	- Q â†’ What is the insertion-sort procedure?
	- A â†’ Recursively sort first nâ€“1 items; insert nth item into correct position.
- Insertion Sort â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(nÂ²), but efficient on nearly sorted input (almost Î˜(n)).
- Insertion Sort â€” pros & cons #card
	- Q â†’ Pros and cons?
	- A â†’
	  **Pros:** stable, simple, adaptive
	  **Cons:** poor on large random data
	  
	  ---
- ## **Topological Sort (DFS version)**
	- Topological Sort â€” problem #card
	- Q â†’ What is topological sorting?
	- A â†’ Ordering vertices of DAG such that all edges go from earlier to later vertices.
- Topological Sort â€” decrease-by-1 algorithm #card
	- Q â†’ What is the simple (source removal) algorithm?
	- A â†’ Repeatedly remove a source (in-degree 0), append to output, delete outgoing edges.
- Topological Sort â€” complexity #card
	- Q â†’ Efficiency?
	- A â†’ Î˜(V + E) using adjacency list.
- Topological Sort â€” improvement #card
	- Q â†’ Improvements?
	- A â†’ Use Kahnâ€™s algorithm or DFS finishing times.
	  
	  ---
- ## **Generating Subsets (Powerset)**
	- Powerset â€” decrease-by-1 #card
	- Q â†’ How is the powerset generated via decrease-by-1?
	- A â†’ Recursively generate subsets of first nâ€“1 elements; duplicate them all with element an added.
- Powerset â€” brute force alternative #card
	- Q â†’ What is the bitstring method?
	- A â†’ Count from 0..2â¿â€“1; interpret binary representation as subset membership.
	  
	  ---
- ## **Generating Permutations**
	- Permutations â€” decrease-by-1 #card
	- Q â†’ How to generate permutations via decrease-by-1?
	- A â†’ Generate permutations of 1..nâ€“1; insert n into each possible position.
- Permutations â€” minimal-change (Johnson-Trotter) #card
	- Q â†’ What is Johnsonâ€“Trotter?
	- A â†’ Generates permutations by repeatedly moving the largest mobile element and flipping directions of larger elements.
	  
	  ---
- ## **Fake Coin Problem**
	- Fake Coin â€” 2-pile version #card
	- Q â†’ How does the 2-pile fake-coin algorithm work?
	- A â†’ Split n coins into two halves; weigh them; recurse into the lighter side.
- Fake Coin â€” 3-pile version #card
	- Q â†’ How does the 3-pile version work?
	- A â†’ Split into 3 piles; weigh first two; if equal, continue with third; else recurse on lighter pile.
- Fake Coin â€” efficiencies #card
	- Q â†’ Complexity?
	- A â†’
		- 2-pile: Î˜(logâ‚‚ n)
		- 3-pile: Î˜(logâ‚ƒ n) (faster)
		  
		  ---
- ## **Russian Peasant Multiplication (a la Russe)**
	- Russe multiplication â€” algorithm #card
	- Q â†’ What is the a-la-Russe multiplication algorithm?
	- A â†’ Repeatedly halve n and double m; if n is odd add m to result.
- Russe â€” complexity #card
	- Q â†’ Efficiency?
	- A â†’ Î˜(log n), because halving repeats ~logâ‚‚ n times.
- ## **Divide & Conquer â€” Concept**
-
- Divide & Conquer â€” definition #card
	- Q â†’ What is the divide-and-conquer strategy?
	- A â†’ A problem is recursively divided into smaller subproblems, each solved independently, and combined to form the final solution.
-
- Divide & Conquer â€” recurrence #card
	- Q â†’ What form do divide-and-conquer recurrences usually take?
	- A â†’ T(n) = aÂ·T(n/b) + f(n), where aâ‰¥1, bâ‰¥2.
-
- ---
-
- ## **Merge Sort**
-
- MergeSort â€” steps #card
	- Q â†’ What are the steps of MergeSort?
	- A â†’
		- 1. Divide array into two halves.
		- 2. Recursively sort each half.
		- 3. Merge the sorted halves.
-
- MergeSort â€” complexity #card
	- Q â†’ What is the time complexity of MergeSort?
	- A â†’ Î˜(n log n) in all cases.
-
- MergeSort â€” space #card
	- Q â†’ What is MergeSort's space cost?
	- A â†’ Î˜(n) auxiliary space.
-
- MergeSort â€” pros & cons #card
	- Q â†’ What are its pros & cons?
	- A â†’
		- **Pros:** stable, predictable performance.
		- **Cons:** needs extra memory; slower than QuickSort in practice.
-
- ---
-
- ## **QuickSort**
-
- QuickSort â€” steps #card
	- Q â†’ What are the steps of QuickSort?
	- A â†’
		- 1. Choose pivot.
		- 2. Partition into â‰¤pivot and >pivot.
		- 3. Recursively sort partitions.
-
- QuickSort â€” average/worst #card
	- Q â†’ What is QuickSort's complexity?
	- A â†’
		- Average: Î˜(n log n)
		- Worst case: Î˜(nÂ²) (occurs with skewed pivot choices)
-
- QuickSort â€” improvements #card
	- Q â†’ How can QuickSort be improved?
	- A â†’
		- Median-of-three pivot
		- Switch to insertion sort for small subarrays
		- Tail recursion elimination
-
- QuickSort â€” stability #card
	- Q â†’ Is QuickSort stable?
	- A â†’ No, classic QuickSort is unstable.
-
- ---
-
- ## **Strassenâ€™s Matrix Multiplication**
-
- Strassen â€” idea #card
	- Q â†’ What is the key idea in Strassen's algorithm?
	- A â†’ Reduce the number of matrix multiplications from 8 to 7 using clever algebraic identity.
-
- Strassen â€” complexity #card
	- Q â†’ What is Strassen's complexity?
	- A â†’ Î˜(nÂ²Â·â¸Â¹â°â·) â‰ˆ Î˜(nÂ²Â·â¸Â¹).
-
- Strassen â€” pros & cons #card
	- Q â†’ Pros & cons?
	- A â†’
		- **Pros:** faster asymptotics for large n.
		- **Cons:** numerically unstable, large overhead, only good for huge matrices.
-
- ---
-
- # ðŸ”µ **GEOMETRIC DIVIDE & CONQUER**
-
- ---
-
- ## **Closest Pair of Points (D&C)**
-
- Closest Pair â€” steps #card
	- Q â†’ Steps of divide-and-conquer closest-pair algorithm?
	- A â†’
		- 1. Sort by x.
		- 2. Split into left/right halves.
		- 3. Recursively find dl and dr.
		- 4. Let d = min(dl, dr).
		- 5. Check the â€œstripâ€ region of width 2d.
		- 6. Compare each point to next â‰¤ 5 points (packing lemma).
-
- Closest Pair â€” strip property #card
	- Q â†’ Why only check the next 5â€“6 points in the strip?
	- A â†’ Packing argument: only 6 points can fit within distance d in the critical region.
-
- Closest Pair â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(n log n).
-
- ---
-
- ## **QuickHull**
-
- QuickHull â€” concept #card
	- Q â†’ What is QuickHull?
	- A â†’ A divide-and-conquer convex hull algorithm analogous to QuickSort: find extreme points, recursively compute upper and lower hulls.
-
- QuickHull â€” complexity #card
	- Q â†’ Complexity?
	- A â†’
		- Worst case: Î˜(nÂ²)
		- Average: Î˜(n)
-
- ---
-
- # ðŸ”µ **TRANSFORM & CONQUER**
-
- ---
-
- ## **Transform & Conquer â€” Concept**
-
- Transform & Conquer â€” definition #card
	- Q â†’ What is transform-and-conquer?
	- A â†’ Transform the problem instance into a simpler or more convenient representation, solve it, and possibly reverse-transform the result.
-
- Transform & Conquer â€” categories #card
	- Q â†’ What are its three forms?
	- A â†’
		- 1. **Instance Simplification**
		- 2. **Representation Change**
		- 3. **Problem Reduction**
-
- ---
-
- ## **INSTANCE SIMPLIFICATION**
-
- ### **Presorting**
-
- Presorting â€” idea #card
	- Q â†’ What is the idea behind presorting?
	- A â†’ Sort the data to make later operations more efficient.
-
- Presorting â€” when beneficial #card
	- Q â†’ When is presorting beneficial?
	- A â†’ When post-sorting algorithms drop from Î˜(nÂ²) to Î˜(n) or similar.
-
- Presorting â€” not useful cases #card
	- Q â†’ When is presorting *not* beneficial?
	- A â†’ When the original algorithm is already Î˜(n), e.g., finding min/max.
-
- ---
-
- ### **Gaussian Elimination**
-
- Gaussian â€” steps #card
	- Q â†’ Steps of Gaussian elimination?
	- A â†’
		- 1. Forward elimination â†’ upper triangular matrix (Î˜(nÂ³)).
		- 2. Backward substitution (Î˜(nÂ²)).
-
- Gaussian â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(nÂ³).
-
- ---
-
- ## **REPRESENTATION CHANGE**
-
- ### **Hornerâ€™s Rule**
-
- Hornerâ€™s Rule â€” idea #card
	- Q â†’ What is Hornerâ€™s rule?
	- A â†’ Rewrite polynomial to minimise multiplications via nested evaluation.
-
- Hornerâ€™s Rule â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(n) vs brute force Î˜(nÂ²).
-
- ### **Binary Exponentiation**
-
- Binary Exponentiation â€” concept #card
	- Q â†’ What is binary (fast) exponentiation?
	- A â†’ Represent exponent in binary; square repeatedly and multiply when encountering a 1 bit.
-
- Binary Exponentiation â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(log n).
-
- ---
-
- ## **PROBLEM REDUCTION**
-
- ### **Least Common Multiple via GCD**
-
- LCM via GCD â€” reduction #card
	- Q â†’ How do we compute LCM via problem reduction?
	- A â†’ LCM(m,n) = (mÂ·n) / GCD(m,n).
-
- ### **State-Space Graph Reductions**
-
- State-space graph â€” reduction #card
	- Q â†’ What is a state-space reduction?
	- A â†’ Convert problem states into a graph; edges represent legal transitions; solve via BFS/DFS.
-
- ---
-
- # ðŸ”µ **SPACEâ€“TIME TRADEOFFS**
-
- ---
-
- ## **General Idea**
-
- Spaceâ€“Time Tradeoff â€” concept #card
	- Q â†’ What is the spaceâ€“time tradeoff?
	- A â†’ Using extra memory (tables, preprocessing) to reduce computation time.
-
- ---
-
- ## **Counting Sort**
-
- Counting Sort â€” idea #card
	- Q â†’ Basic idea of counting sort?
	- A â†’ Count frequency of each integer in range [L, U], compute cumulative distribution, output sorted array.
-
- Counting Sort â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(n + k), where k = Uâ€“L+1.
-
- Counting Sort â€” constraints #card
	- Q â†’ What are the constraints?
	- A â†’ Only works for integer keys within small range.
-
- ---
-
- ## **Horspoolâ€™s String Matching**
-
- Horspool â€” key idea #card
	- Q â†’ Key ideas of Horspool's algorithm?
	- A â†’ Compare pattern from right to left, and use bad-symbol shift table to skip ahead more than 1 char.
-
- Horspool â€” shift table #card
	- Q â†’ How is the shift table computed?
	- A â†’ T(c) = m if c not in pattern; else mâ€“1â€“rightmost_index(c).
-
- Horspool â€” complexity #card
	- Q â†’ Efficiency?
	- A â†’
		- Worst: Î˜(mn)
		- Average: Î˜(n/m), extremely fast in practice.
-
- ---
-
- ## **Boyerâ€“Moore**
-
- Boyerâ€“Moore â€” idea #card
	- Q â†’ What are the two shift rules in Boyerâ€“Moore?
	- A â†’ Bad-symbol rule + Good-suffix rule.
-
- BM â€” bad-symbol shift #card
	- Q â†’ What is the bad-symbol shift formula?
	- A â†’ max(T(c) â€“ k, 1) where k is matched chars count.
-
- BM â€” good-suffix cases #card
	- Q â†’ What are the good-suffix rule cases?
	- A â†’
		- 1. No other occurrence â†’ shift m
		- 2. Occurs earlier â†’ align with rightmost occurrence
		- 3. Prefix matches suffix â†’ shift accordingly
-
- BM â€” efficiency #card
	- Q â†’ Efficiency?
	- A â†’ Sublinear on average; worst case Î˜(m+n).
-
- ---
-
- # ðŸ”µ **DYNAMIC PROGRAMMING**
-
- ---
-
- ## **Dynamic Programming â€” Principle**
-
- DP â€” definition #card
	- Q â†’ What is dynamic programming?
	- A â†’ Solve overlapping subproblems; store results; use recurrence relations.
-
- DP â€” optimality #card
	- Q â†’ What is the principle of optimality?
	- A â†’ An optimal solution contains optimal solutions to its subproblems.
-
- ---
-
- ## **Fibonacci DP**
-
- Fibonacci â€” recurrence #card
	- Q â†’ Fibonacci recurrence?
	- A â†’ F(n) = F(nâ€“1) + F(nâ€“2).
-
- Fibonacci â€” DP solution #card
	- Q â†’ DP solution complexity?
	- A â†’ Î˜(n).
-
- ---
-
- ## **Change-Making Problem**
-
- Change-making â€” recurrence #card
	- Q â†’ Recurrence relation?
	- A â†’
		- F(0) = 0
		- F(n) = min_j { F(n â€“ d_j) } + 1
-
- Change-making â€” DP complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(nm), where m = number of denominations.
-
- ---
-
- ## **Robot Coin Collection**
-
- Robot coin â€” recurrence #card
	- Q â†’ Recurrence?
	- A â†’
		- F(i,j) = max(F(iâ€“1,j), F(i,jâ€“1)) + c_ij
-
- Robot coin â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(nm) + backtrace Î˜(n+m).
-
- ---
-
- ## **Transitive Closure (Warshall)**
-
- Warshall â€” idea #card
	- Q â†’ What is the Warshall algorithm?
	- A â†’ Uses DP to determine if path exists from i to j through intermediate vertices 1..k.
-
- Warshall â€” recurrence #card
	- Q â†’ Recurrence?
	- A â†’
		- R_k[i,j] = R_{kâ€“1}[i,j] OR (R_{kâ€“1}[i,k] AND R_{kâ€“1}[k,j])
-
- Warshall â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(nÂ³).
-
- ---
-
- ## **Floydâ€™s All-Pairs Shortest Paths**
-
- Floyd â€” recurrence #card
	- Q â†’ Floydâ€™s recurrence?
	- A â†’
		- D_k[i,j] = min(D_{kâ€“1}[i,j], D_{kâ€“1}[i,k] + D_{kâ€“1}[k,j])
-
- Floyd â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(nÂ³).
-
- ---
-
- ## **Knapsack (DP version)**
-
- Knapsack DP â€” table meaning #card
	- Q â†’ What does DP[i,w] represent?
	- A â†’ Maximum value achievable with first i items and capacity w.
-
- Knapsack DP â€” recurrence #card
	- Q â†’ Recurrence?
	- A â†’
		- If weight_i > w â†’ DP[i,w] = DP[iâ€“1,w]
		- Else DP[i,w] = max(DP[iâ€“1,w], DP[iâ€“1,wâ€“weight_i] + value_i)
-
- Knapsack DP â€” complexity #card
	- Q â†’ Complexity?
	- A â†’ Î˜(nW).